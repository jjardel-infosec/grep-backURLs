

ðŸš€ Project Name : grep-backURLs
===============

#### grep-backURLs : Automated way to find juicy information from website 

### ðŸ“Œ Overview


 *_grep-backURLs_* is a web security automation tool to extracts important credentials in bug hunting. It uses subfinder to find subdomains and then those subdomain acts as input links for waybackurls . After that , it uses grep command and keywords.txt to sort out important credentials.

### ðŸ¤” Why This Name?

 Just beacuse it uses grep command to sort out from waybackURLs link.


### âŒš Total Time taken to build & test

 Approx 3-3:30 hr.

### ðŸ™ƒWhy I Created This

 Cause I don't want to waste my time to find subdomains and then try each keyword from keyword.txt to check whether is there any credential or not, so decided to automate it.

### ðŸ“š  Requirements & Dependencies

* #### Golang
* #### [waybackurls](https://github.com/tomnomnom/waybackurls)
* #### [subfinder](https://github.com/projectdiscovery/subfinder)

### ðŸ“¥ Installation Guide

#### âš¡ Quick Install:

 1. Git clone this URL.
 2. Go to grep-backURls directory and give permission to main.go
 3. Run command ./main.go

### ðŸ’“ Credits:


 * #### [@tomnomnom](https://github.com/tomnomnom) for developing waybackurls
* ####  [@project discovery](https://github.com/projectdiscovery)for creating subfinder.
* #### Sathvik and his [video](https://www.youtube.com/watch?v=lp4Do_VIwzw)  for inspiration. 



### ðŸ“ž Contact


 ðŸ“§ Email: jose@jardel.tec.br


 ### Update
* Add creation of subfolders within the main folder, to separate domains that you are looking for bounty.


### ðŸ“„ License

Licensed under **MIT**

ðŸ•’ Last Updated: February 23, 2025 
